# **Netflix Movies And TV Shows Database - An Exploration**

This is a work in progress. The final aim is to create a recommendation system where, given a particular movie or TV show,
a list of related shows will be generated by the system.

Initially, each individual column of the dataset is being considered separately to generate recommendations. The final aim is to
combine the analysis on each column using a weighting system to generate recommendations based on all the available data.

## **The Dataset**

The Netflix Movies and TV Shows dataset was obtained from Kaggle. It contains a mixture of different data types, including categorical,
textual etc. This dataset presents quite an interesting data cleaning challenge, due to the existence of null values.

A brief description of how I handled this task -

1. There were 2 major data types after reading in the .csv file as a Pandas dataframe - int64 and Object
2. I have replaced null values for the int64 columns by 0, and Objects by the string 'unknown' for now. When more complicated analysis is
done later, more thought is required about these. They are fine as placeholders for now.
3. A lot of the cells in the dataframe had a large number of values, separated by commas, which made them hard to parse. I have converted
them into lists for ease of access and usage.
4. There is a column called 'show_id' in the dataset which is fully populated, and unique for each entry. For obvious reasons, this
column lends itself very well to being used as a Primary Key when accessing entries in the data (here, I am considering the dataset as a
database, mostly because in a real-world scenario, models that generate recommendations will pull from existing databases, and not
individual files!)
5. Finally, I have converted the dataframe of data into a nested dictionary, so as to fully utilise the show_id column as the
keys. Each key in the top level of the dictionary is the show_id, and the values are separate dictionaries containing the
rest of the data for that particular show, with the column names as the keys.
6. I have written out this data as a json file, to make it accessible for further work, and because, realistically, this cleaning
exercise wouldn't be performed every time the model is run.

The cleandata.py script in the data-cleaning and text-similarity branches contain this work.


## **Recommendations Based On Cast**

The first column to be tackled was the 'Cast' column. The aim was to generate a set of recommendations based on a
chosen movie/show, solely based on cast. The work done on this column can be found on the text-similarity branch.

The metric used to calculate similarity between shows based on cast was the Jaccard Similarity. There are some obvious
disadvantages of the Jaccard similarity (https://medium.com/@adriensieg/text-similarities-da019229c894 is a very good article,
in my opinion), but for the purposes of comparing cast, I feel these flaws (lack of semantic similarity consideration and huge
sizes of documents) are not as problematic. This is mainly because semantic similarity for proper nouns isn't really
applicable, and a document of cast names should never be prohibitively large (unless you think about the
number of extras in the Lord Of The Rings movies, in which case it'll be a close call!!).

A brief description of this analysis -

1. As mentioned before, nulls were replaced by 'unknown' for non-integer data. For shows where cast information was
unavailable, I have removed those keys from the dictionary. Later work could include a better way of handling these.
2. In get_individual_similarities.py, I have created a nested dictionary containing cast similarity information.
3. The keys of the outer dictionary are the show_id values, and each inner dictionary are the shows which have a non-zero
Jaccard Similarity with that particular show. While generating this dictionary, I only considered non-zero similarities,
which was not only logical, but also very important from a practical point of view.
4. Not really a new point, but I really like the dictionary comprehension I used for this! ;)
5. Recommendations are generated in the imaginatively named generate_recommendations.py script. To simulate how users would
watch a particular show and expect recommendations based on that, I have added a line to choose a show at random and generate
recommendations for that.
6. I have been generating 3 recommendations for each choice, and in cases where 3 don't exist, I have added handlers to
take care of those scenarios.

I am currently working on looking at the country data for recommendations, and there is also a lot of scope for refinement
of this work.
